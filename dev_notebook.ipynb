{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "# from bert import run_classifier\n",
    "# from bert import optimization\n",
    "from bert import tokenization\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import os\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "from tensorflow.metrics import accuracy\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def span_accuracy(predictions, positions, n_way=5):\n",
    "    \"\"\"\n",
    "    Exact span match.\n",
    "    :param predictions: [batch_size, 2]\n",
    "    :param positions: [batch_size, 5, 2]\n",
    "    :return: a tuple of:\n",
    "        accuracy: A `Tensor` representing the accuracy, the value of `total` divided\n",
    "          by `count`.\n",
    "        update_op: An operation that increments the `total` and `count` variables\n",
    "          appropriately and whose value matches `accuracy`.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = tf.stack(n_way * [predictions], axis=1)\n",
    "    is_correct = tf.reduce_any(tf.equal(tf.reduce_sum(tf.cast(math_ops.equal(predictions, positions), tf.int64),axis=-1), 2),axis=-1)\n",
    "    return is_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=666, shape=(3, 5, 2), dtype=int32, numpy=\n",
       "array([[[ 1,  2],\n",
       "        [ 4,  5],\n",
       "        [ 3,  5],\n",
       "        [ 3,  5],\n",
       "        [ 1,  5]],\n",
       "\n",
       "       [[10, 11],\n",
       "        [10, 11],\n",
       "        [ 9, 12],\n",
       "        [ 3,  5],\n",
       "        [ 3,  5]],\n",
       "\n",
       "       [[30, 31],\n",
       "        [29, 39],\n",
       "        [ 9, 12],\n",
       "        [ 3,  5],\n",
       "        [ 3,  5]]], dtype=int32)>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import metrics\n",
    "n_way = 5\n",
    "predictions = tf.constant([[1,2],[10,12],[30,30]])\n",
    "positions = tf.constant([[[1,2],[4,5],[3,5],[3,5],[1,5]],\n",
    "                        [[10,11],[10,11],[9,12],[3,5],[3,5]],\n",
    "                        [[30,31],[29,39],[9,12],[3,5],[3,5]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=787, shape=(4,), dtype=bool, numpy=array([ True, False, False,  True])>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_accuracy = span_accuracy(predictions, positions)\n",
    "_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=1529, shape=(), dtype=float64, numpy=0.5>,\n",
       " <tf.Tensor: id=1533, shape=(), dtype=float64, numpy=0.5>)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################\n",
    "# precision / recall#\n",
    "#####################\n",
    "predictions = tf.constant([[0,0], [1,2], [0,0], [30,30]]) # TN, FP, FN, TP,  \n",
    "positions = tf.constant([[[0,0],[0,0],[0,0],[0,0],[0,0]],\n",
    "                         [[0,0],[0,0],[0,0],[0,0],[0,0]],\n",
    "                        [[10,12],[10,11],[9,12],[3,5],[3,5]],\n",
    "                        [[30,30],[29,39],[9,12],[3,5],[3,5]]])\n",
    "_accuracy = span_accuracy(predictions, positions)\n",
    "_equal = tf.cast(math_ops.equal(positions, 0), tf.int64)\n",
    "labels = tf.reduce_any(tf.not_equal(tf.reduce_sum(_equal, axis=-1), 2), -1)\n",
    "labels\n",
    "tp = tf.reduce_sum(tf.cast(math_ops.logical_and(math_ops.equal(_accuracy, True), math_ops.equal(labels, False)), tf.int64))\n",
    "fp = tf.reduce_sum(tf.cast(math_ops.logical_and(math_ops.equal(_accuracy, True), math_ops.equal(labels, True)), tf.int64))\n",
    "fn = tf.reduce_sum(tf.cast(math_ops.logical_and(math_ops.equal(_accuracy, False), math_ops.equal(labels, True)), tf.int64))\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "precision, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=882, shape=(4,), dtype=bool, numpy=array([False,  True, False,  True])>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = math_ops.logical_and(math_ops.equal(labels, True), math_ops.equal(predictions, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_l = tf.constant([[0.1, 0.4, 0.5],[0.1, 0.4, 0.5],[0.1, 0.9, 0.5]])\n",
    "end_l = tf.constant([[0.1, 0.4, 0.5],[0.5, 0.4, 0.1],[0.1, 0.9, 0.5]])\n",
    "\n",
    "start_l = tf.math.exp(start_l)\n",
    "end_l = tf.math.exp(end_l)\n",
    "start_l = tf.expand_dims(start_l, 1)\n",
    "end_l = tf.expand_dims(end_l, -1)\n",
    "#TODO: mask end preceeding statt.\n",
    "logits = start_l * end_l\n",
    "flat_logits = tf.reshape(logits, shape=[tf.shape(logits)[0], -1])\n",
    "logits = tf.linalg.LinearOperatorLowerTriangular(logits).to_dense()\n",
    "flat_logits = tf.reshape(logits, shape=[tf.shape(logits)[0], -1])\n",
    "_argmax = tf.cast(tf.argmax(flat_logits, axis=-1), dtype=tf.int32)\n",
    "ix = tf.cast(tf.stack([_argmax % tf.shape(logits)[1], _argmax // tf.shape(logits)[2]], axis=-1), dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "### Testing the preprocessing module   ###\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.preprocessing import convert_example\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                                  tokenization_info[\"do_lower_case\"]])\n",
    "\n",
    "    return bert.tokenization.FullTokenizer(\n",
    "        vocab_file=vocab_file, do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /var/folders/lc/hb9bf06j1rxbfpk731_nt7g40000gp/T/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "token = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/Users/deniz/natural_questions/data/v1.0_sample_nq-dev-sample.jsonl:0\n",
      "INFO:tensorflow:[(0, (276, 279))]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "[(276, 279)] has type list, but expected one of: int, long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-81c3b4cb990a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                              \u001b[0mdoc_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                              \u001b[0mmax_query_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                              train_writer=train_writer.process_feature)\n\u001b[0m",
      "\u001b[0;32m~/natural_questions/preprocessing/preprocessing.py\u001b[0m in \u001b[0;36mconvert_example\u001b[0;34m(example, tokenizer, max_seq_length, doc_stride, max_query_length, mode, downsample_null_instances, train_writer)\u001b[0m\n\u001b[1;32m    362\u001b[0m                                     tokens=tokens)\n\u001b[1;32m    363\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrain_writer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m               \u001b[0mtrain_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/natural_questions/preprocessing/preprocessing.py\u001b[0m in \u001b[0;36mprocess_feature\u001b[0;34m(self, feature)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m       \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"positions\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_int_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m       \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answer_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_int_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/natural_questions/preprocessing/preprocessing.py\u001b[0m in \u001b[0;36mcreate_int_feature\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_int_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m       feature = tf.train.Feature(\n\u001b[0;32m---> 60\u001b[0;31m           int64_list=tf.train.Int64List(value=list(values)))\n\u001b[0m\u001b[1;32m     61\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: [(276, 279)] has type list, but expected one of: int, long"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import re\n",
    "from preprocessing.preprocessing import FeatureWriter\n",
    "_train_file = '/Users/deniz/natural_questions/data/v1.0_sample_nq-train-sample.jsonl'\n",
    "_dev_file = '/Users/deniz/natural_questions/data/v1.0_sample_nq-dev-sample.jsonl'\n",
    "_train_file_out = re.sub(\".jsonl\", \".tf_record\", _train_file)\n",
    "train_writer = FeatureWriter(\n",
    "    filename=_train_file_out,\n",
    "    mode='train')\n",
    "with jsonlines.open(_train_file) as reader:\n",
    "    features, examples = [], []\n",
    "    for i, example in enumerate(reader):\n",
    "        if i % 1e3 == 0: tf.logging.info(\"{}:{}\".format(_dev_file, i))\n",
    "        examples.append(example)\n",
    "        dt = convert_example(example=example,\n",
    "                             tokenizer=token,\n",
    "                             mode='train',\n",
    "                             max_seq_length=384,\n",
    "                             doc_stride=128,\n",
    "                             max_query_length=64,\n",
    "                             train_writer=train_writer.process_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "### JSON files  ###\n",
    "##########################################\n",
    "a = [(10,20),(10,40)]\n",
    "b = list(sum(a, ()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "_train_file = '/Users/deniz/natural_questions/data/v1.0_sample_nq-train-sample.jsonl'\n",
    "_dev_file = '/Users/deniz/natural_questions/data/v1.0_sample_nq-dev-sample.jsonl'\n",
    "with jsonlines.open(_train_file) as reader:\n",
    "    features, train_examples = [], []\n",
    "    for i, example in enumerate(reader):\n",
    "        train_examples.append(example['annotations'])\n",
    "\n",
    "            \n",
    "_train_file = '/Users/deniz/natural_questions/data/v1.0_sample_nq-train-sample.jsonl'\n",
    "_dev_file = '/Users/deniz/natural_questions/data/v1.0_sample_nq-dev-sample.jsonl'\n",
    "with jsonlines.open(_dev_file) as reader:\n",
    "    features, dev_examples = [], []\n",
    "    for i, example in enumerate(reader):\n",
    "        dev_examples.append(example['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({1: 200}), Counter({5: 200}))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([len(t) for t in train_examples]), Counter([len(t) for t in dev_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'annotation_id': 4831085488325731996,\n",
       "  'long_answer': {'candidate_index': -1,\n",
       "   'end_byte': -1,\n",
       "   'end_token': -1,\n",
       "   'start_byte': -1,\n",
       "   'start_token': -1},\n",
       "  'short_answers': [],\n",
       "  'yes_no_answer': 'NONE'},\n",
       " {'annotation_id': 11617036854844010808,\n",
       "  'long_answer': {'candidate_index': -1,\n",
       "   'end_byte': -1,\n",
       "   'end_token': -1,\n",
       "   'start_byte': -1,\n",
       "   'start_token': -1},\n",
       "  'short_answers': [],\n",
       "  'yes_no_answer': 'NONE'},\n",
       " {'annotation_id': 15568189459232688585,\n",
       "  'long_answer': {'candidate_index': -1,\n",
       "   'end_byte': -1,\n",
       "   'end_token': -1,\n",
       "   'start_byte': -1,\n",
       "   'start_token': -1},\n",
       "  'short_answers': [],\n",
       "  'yes_no_answer': 'NONE'},\n",
       " {'annotation_id': 10333790090572531291,\n",
       "  'long_answer': {'candidate_index': -1,\n",
       "   'end_byte': -1,\n",
       "   'end_token': -1,\n",
       "   'start_byte': -1,\n",
       "   'start_token': -1},\n",
       "  'short_answers': [],\n",
       "  'yes_no_answer': 'NONE'},\n",
       " {'annotation_id': 15453965265736125661,\n",
       "  'long_answer': {'candidate_index': -1,\n",
       "   'end_byte': -1,\n",
       "   'end_token': -1,\n",
       "   'start_byte': -1,\n",
       "   'start_token': -1},\n",
       "  'short_answers': [],\n",
       "  'yes_no_answer': 'NONE'}]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_examples[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 130, 1: 69, 3: 1})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiple short answers per annotation\n",
    "Counter([len(t[0]['short_answers']) for t in train_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'annotation_id': 10957934160137332476,\n",
       "  'long_answer': {'candidate_index': -1,\n",
       "   'end_byte': -1,\n",
       "   'end_token': -1,\n",
       "   'start_byte': -1,\n",
       "   'start_token': -1},\n",
       "  'short_answers': [],\n",
       "  'yes_no_answer': 'NONE'},\n",
       " {'annotation_id': 2807704282985816749,\n",
       "  'long_answer': {'candidate_index': -1,\n",
       "   'end_byte': -1,\n",
       "   'end_token': -1,\n",
       "   'start_byte': -1,\n",
       "   'start_token': -1},\n",
       "  'short_answers': [],\n",
       "  'yes_no_answer': 'NONE'},\n",
       " {'annotation_id': 5129692602407601925,\n",
       "  'long_answer': {'candidate_index': 0,\n",
       "   'end_byte': 57005,\n",
       "   'end_token': 122,\n",
       "   'start_byte': 56251,\n",
       "   'start_token': 43},\n",
       "  'short_answers': [],\n",
       "  'yes_no_answer': 'NONE'},\n",
       " {'annotation_id': 4965838886380681126,\n",
       "  'long_answer': {'candidate_index': 90,\n",
       "   'end_byte': 104818,\n",
       "   'end_token': 4593,\n",
       "   'start_byte': 104066,\n",
       "   'start_token': 4485},\n",
       "  'short_answers': [{'end_byte': 104576,\n",
       "    'end_token': 4570,\n",
       "    'start_byte': 104572,\n",
       "    'start_token': 4569},\n",
       "   {'end_byte': 104639,\n",
       "    'end_token': 4572,\n",
       "    'start_byte': 104633,\n",
       "    'start_token': 4571}],\n",
       "  'yes_no_answer': 'NONE'},\n",
       " {'annotation_id': 9518639313383123593,\n",
       "  'long_answer': {'candidate_index': -1,\n",
       "   'end_byte': -1,\n",
       "   'end_token': -1,\n",
       "   'start_byte': -1,\n",
       "   'start_token': -1},\n",
       "  'short_answers': [],\n",
       "  'yes_no_answer': 'NONE'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_examples[-2]['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2975172535563055798"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = features[10]\n",
    "feature.example_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(i):\n",
    "    feature = features[i]\n",
    "    example_id = feature.example_id\n",
    "    example = [x for x in examples if x['example_id'] == example_id][0]\n",
    "    return feature, example  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(example):\n",
    "    \"\"\"\n",
    "    if short, else long\n",
    "    \"\"\"\n",
    "    annotation = example['annotations'][0]\n",
    "    end_byte_ix, start_byte_ix = None, None\n",
    "    start_token, end_token = None, None\n",
    "    if annotation['short_answers']:\n",
    "        end_byte_ix = annotation['short_answers'][0]['end_byte']\n",
    "        start_token = annotation['short_answers'][0]['start_token']\n",
    "        end_token = annotation['short_answers'][0]['end_token']\n",
    "        start_byte_ix = annotation['short_answers'][0]['start_byte']\n",
    "    else:\n",
    "        end_byte_ix = annotation['long_answer']['end_byte']\n",
    "        start_byte_ix = annotation['long_answer']['start_byte']\n",
    "        start_token = annotation['long_answer']['start_token']\n",
    "        end_token = annotation['long_answer']['end_token']\n",
    "    return {'end_byte_ix': end_byte_ix, \n",
    "            'start_byte_ix': start_byte_ix,\n",
    "            'start_token': start_token,\n",
    "            'end_token': end_token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate(i):\n",
    "    # get the feature and example the feature is derived from.\n",
    "    feature, example = test(i)\n",
    "    # get the ground truth annotations.\n",
    "    gt = get_annotations(example)\n",
    "    # get start byte and end bytes for targets.\n",
    "    if feature.targets[0] == 0:\n",
    "        return (i, True)\n",
    "    start_bytes = feature.start_bytes[feature.targets[0]]\n",
    "    end_bytes = feature.end_bytes[feature.targets[1]]\n",
    "    if start_bytes == gt['start_byte_ix'] and end_bytes == gt['end_byte_ix']:\n",
    "        return (i,True)\n",
    "    else:\n",
    "        return (i, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'end_byte_ix': 96731, 'start_byte_ix': 96715, 'start_token': 3521, 'end_token': 3525}\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, True)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature, example = test(1)\n",
    "gt = get_annotations(example)\n",
    "print(gt)\n",
    "start_bytes = feature.start_bytes[feature.targets[0]]\n",
    "end_bytes = feature.end_bytes[feature.targets[1]]\n",
    "feature.targets, start_bytes, end_bytes\n",
    "_validate(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = []\n",
    "for i in range(len(features)):\n",
    "    _assertion =  _validate(i)\n",
    "    if not _assertion[1]:\n",
    "        ix.append(i)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth\n",
      "{'end_byte_ix': 55798, 'start_byte_ix': 55137, 'start_token': 893, 'end_token': 1001}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55140, 55794)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assertion fails\n",
    "feature, example = test(ix[2])\n",
    "gt = get_annotations(example)\n",
    "print('ground truth')\n",
    "print(gt)\n",
    "start_bytes = feature.start_bytes[feature.targets[0]]\n",
    "end_bytes = feature.end_bytes[feature.targets[1]]\n",
    "start_bytes, end_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'annotation_id': 13306123758205215060,\n",
       "  'long_answer': {'candidate_index': 32,\n",
       "   'end_byte': 55798,\n",
       "   'end_token': 1001,\n",
       "   'start_byte': 55137,\n",
       "   'start_token': 893},\n",
       "  'short_answers': [],\n",
       "  'yes_no_answer': 'NONE'}]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'end_byte': 55140, 'html_token': True, 'start_byte': 55137, 'token': '<P>'},\n",
       " {'end_byte': 55143, 'html_token': False, 'start_byte': 55140, 'token': 'The'},\n",
       " {'end_byte': 55153,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55144,\n",
       "  'token': 'marooning'},\n",
       " {'end_byte': 55156, 'html_token': False, 'start_byte': 55154, 'token': 'of'},\n",
       " {'end_byte': 55167,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55160,\n",
       "  'token': 'Voyager'},\n",
       " {'end_byte': 55174, 'html_token': False, 'start_byte': 55172, 'token': 'in'},\n",
       " {'end_byte': 55178, 'html_token': False, 'start_byte': 55175, 'token': 'the'},\n",
       " {'end_byte': 55184,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55179,\n",
       "  'token': 'Delta'},\n",
       " {'end_byte': 55193,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55185,\n",
       "  'token': 'Quadrant'},\n",
       " {'end_byte': 55202,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55194,\n",
       "  'token': 'provided'},\n",
       " {'end_byte': 55208,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55203,\n",
       "  'token': 'Paris'},\n",
       " {'end_byte': 55213,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55209,\n",
       "  'token': 'with'},\n",
       " {'end_byte': 55215, 'html_token': False, 'start_byte': 55214, 'token': 'a'},\n",
       " {'end_byte': 55219, 'html_token': False, 'start_byte': 55216, 'token': 'new'},\n",
       " {'end_byte': 55229,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55220,\n",
       "  'token': 'beginning'},\n",
       " {'end_byte': 55230, 'html_token': False, 'start_byte': 55229, 'token': '.'},\n",
       " {'end_byte': 55238,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55231,\n",
       "  'token': 'Janeway'},\n",
       " {'end_byte': 55243,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55239,\n",
       "  'token': 'gave'},\n",
       " {'end_byte': 55249,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55244,\n",
       "  'token': 'Paris'},\n",
       " {'end_byte': 55251, 'html_token': False, 'start_byte': 55250, 'token': 'a'},\n",
       " {'end_byte': 55257,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55252,\n",
       "  'token': 'field'},\n",
       " {'end_byte': 55268,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55258,\n",
       "  'token': 'commission'},\n",
       " {'end_byte': 55271, 'html_token': False, 'start_byte': 55269, 'token': 'as'},\n",
       " {'end_byte': 55273, 'html_token': False, 'start_byte': 55272, 'token': 'a'},\n",
       " {'end_byte': 55283,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55274,\n",
       "  'token': 'Starfleet'},\n",
       " {'end_byte': 55294,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55284,\n",
       "  'token': 'lieutenant'},\n",
       " {'end_byte': 55298, 'html_token': False, 'start_byte': 55295, 'token': 'and'},\n",
       " {'end_byte': 55303,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55299,\n",
       "  'token': 'made'},\n",
       " {'end_byte': 55307, 'html_token': False, 'start_byte': 55304, 'token': 'him'},\n",
       " {'end_byte': 55313,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55308,\n",
       "  'token': 'chief'},\n",
       " {'end_byte': 55322,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55314,\n",
       "  'token': 'helmsman'},\n",
       " {'end_byte': 55325, 'html_token': False, 'start_byte': 55323, 'token': 'of'},\n",
       " {'end_byte': 55336,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55329,\n",
       "  'token': 'Voyager'},\n",
       " {'end_byte': 55341, 'html_token': False, 'start_byte': 55340, 'token': '.'},\n",
       " {'end_byte': 55344, 'html_token': False, 'start_byte': 55342, 'token': 'He'},\n",
       " {'end_byte': 55348, 'html_token': False, 'start_byte': 55345, 'token': 'had'},\n",
       " {'end_byte': 55350, 'html_token': False, 'start_byte': 55349, 'token': 'a'},\n",
       " {'end_byte': 55356,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55351,\n",
       "  'token': 'rough'},\n",
       " {'end_byte': 55362,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55357,\n",
       "  'token': 'start'},\n",
       " {'end_byte': 55363, 'html_token': False, 'start_byte': 55362, 'token': ','},\n",
       " {'end_byte': 55371,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55364,\n",
       "  'token': 'however'},\n",
       " {'end_byte': 55372, 'html_token': False, 'start_byte': 55371, 'token': ','},\n",
       " {'end_byte': 55375, 'html_token': False, 'start_byte': 55373, 'token': 'as'},\n",
       " {'end_byte': 55385,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55376,\n",
       "  'token': 'Starfleet'},\n",
       " {'end_byte': 55389, 'html_token': False, 'start_byte': 55386, 'token': 'and'},\n",
       " {'end_byte': 55396,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55390,\n",
       "  'token': 'Maquis'},\n",
       " {'end_byte': 55402,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55397,\n",
       "  'token': 'alike'},\n",
       " {'end_byte': 55409,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55403,\n",
       "  'token': 'viewed'},\n",
       " {'end_byte': 55415,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55410,\n",
       "  'token': 'Paris'},\n",
       " {'end_byte': 55420,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55416,\n",
       "  'token': 'with'},\n",
       " {'end_byte': 55430,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55421,\n",
       "  'token': 'suspicion'},\n",
       " {'end_byte': 55431, 'html_token': False, 'start_byte': 55430, 'token': '.'},\n",
       " {'end_byte': 55437,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55432,\n",
       "  'token': 'Paris'},\n",
       " {'end_byte': 55444,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55438,\n",
       "  'token': 'worked'},\n",
       " {'end_byte': 55449,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55445,\n",
       "  'token': 'hard'},\n",
       " {'end_byte': 55452, 'html_token': False, 'start_byte': 55450, 'token': 'to'},\n",
       " {'end_byte': 55457,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55453,\n",
       "  'token': 'earn'},\n",
       " {'end_byte': 55461, 'html_token': False, 'start_byte': 55458, 'token': 'his'},\n",
       " {'end_byte': 55471,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55462,\n",
       "  'token': 'crewmates'},\n",
       " {'end_byte': 55476, 'html_token': False, 'start_byte': 55471, 'token': \"'\"},\n",
       " {'end_byte': 55484,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55477,\n",
       "  'token': 'respect'},\n",
       " {'end_byte': 55485, 'html_token': False, 'start_byte': 55484, 'token': '.'},\n",
       " {'end_byte': 55492,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55486,\n",
       "  'token': 'During'},\n",
       " {'end_byte': 55497,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55493,\n",
       "  'token': 'this'},\n",
       " {'end_byte': 55502,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55498,\n",
       "  'token': 'time'},\n",
       " {'end_byte': 55503, 'html_token': False, 'start_byte': 55502, 'token': ','},\n",
       " {'end_byte': 55506, 'html_token': False, 'start_byte': 55504, 'token': 'he'},\n",
       " {'end_byte': 55513,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55507,\n",
       "  'token': 'became'},\n",
       " {'end_byte': 55518,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55514,\n",
       "  'token': 'best'},\n",
       " {'end_byte': 55526,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55519,\n",
       "  'token': 'friends'},\n",
       " {'end_byte': 55531,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55527,\n",
       "  'token': 'with'},\n",
       " {'end_byte': 55538,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55532,\n",
       "  'token': 'Ensign'},\n",
       " {'end_byte': 55612,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55607,\n",
       "  'token': 'Harry'},\n",
       " {'end_byte': 55616, 'html_token': False, 'start_byte': 55613, 'token': 'Kim'},\n",
       " {'end_byte': 55621, 'html_token': False, 'start_byte': 55620, 'token': ','},\n",
       " {'end_byte': 55623, 'html_token': False, 'start_byte': 55622, 'token': 'a'},\n",
       " {'end_byte': 55629,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55624,\n",
       "  'token': 'young'},\n",
       " {'end_byte': 55637,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55630,\n",
       "  'token': 'officer'},\n",
       " {'end_byte': 55640, 'html_token': False, 'start_byte': 55638, 'token': 'on'},\n",
       " {'end_byte': 55644, 'html_token': False, 'start_byte': 55641, 'token': 'his'},\n",
       " {'end_byte': 55650,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55645,\n",
       "  'token': 'first'},\n",
       " {'end_byte': 55658,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55651,\n",
       "  'token': 'mission'},\n",
       " {'end_byte': 55662, 'html_token': False, 'start_byte': 55659, 'token': 'who'},\n",
       " {'end_byte': 55669,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55663,\n",
       "  'token': 'defied'},\n",
       " {'end_byte': 55673, 'html_token': False, 'start_byte': 55670, 'token': 'his'},\n",
       " {'end_byte': 55683,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55674,\n",
       "  'token': 'crewmates'},\n",
       " {'end_byte': 55686, 'html_token': False, 'start_byte': 55684, 'token': 'to'},\n",
       " {'end_byte': 55695,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55687,\n",
       "  'token': 'befriend'},\n",
       " {'end_byte': 55701,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55696,\n",
       "  'token': 'Paris'},\n",
       " {'end_byte': 55702, 'html_token': False, 'start_byte': 55701, 'token': '.'},\n",
       " {'end_byte': 55713,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55703,\n",
       "  'token': 'Eventually'},\n",
       " {'end_byte': 55714, 'html_token': False, 'start_byte': 55713, 'token': ','},\n",
       " {'end_byte': 55720,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55715,\n",
       "  'token': 'Paris'},\n",
       " {'end_byte': 55724, 'html_token': False, 'start_byte': 55721, 'token': 'was'},\n",
       " {'end_byte': 55733,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55725,\n",
       "  'token': 'accepted'},\n",
       " {'end_byte': 55736, 'html_token': False, 'start_byte': 55734, 'token': 'by'},\n",
       " {'end_byte': 55740, 'html_token': False, 'start_byte': 55737, 'token': 'the'},\n",
       " {'end_byte': 55745,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55741,\n",
       "  'token': 'crew'},\n",
       " {'end_byte': 55749, 'html_token': False, 'start_byte': 55746, 'token': 'and'},\n",
       " {'end_byte': 55756,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55750,\n",
       "  'token': 'became'},\n",
       " {'end_byte': 55760, 'html_token': False, 'start_byte': 55757, 'token': 'one'},\n",
       " {'end_byte': 55763, 'html_token': False, 'start_byte': 55761, 'token': 'of'},\n",
       " {'end_byte': 55771,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55764,\n",
       "  'token': 'Janeway'},\n",
       " {'end_byte': 55777, 'html_token': False, 'start_byte': 55771, 'token': \"'s\"},\n",
       " {'end_byte': 55784,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55778,\n",
       "  'token': 'valued'},\n",
       " {'end_byte': 55793,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55785,\n",
       "  'token': 'officers'},\n",
       " {'end_byte': 55794, 'html_token': False, 'start_byte': 55793, 'token': '.'},\n",
       " {'end_byte': 55798, 'html_token': True, 'start_byte': 55794, 'token': '</P>'}]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = get_annotations(example)\n",
    "[t for t in example['document_tokens'] if t['start_byte'] >= ann['start_byte_ix'] and t['end_byte'] <= ann['end_byte_ix']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_nq import input_fn_builder\n",
    "seq_length=384\n",
    "\n",
    "name_to_features = {\n",
    "  \"input_ids\": tf.FixedLenFeature([], tf.int64),\n",
    "  \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "  \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "  \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "  \"start_bytes\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "  \"end_bytes\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "}\n",
    "name_to_features[\"start_positions\"] = tf.FixedLenFeature([], tf.int64)\n",
    "name_to_features[\"end_positions\"] = tf.FixedLenFeature([], tf.int64)\n",
    "\n",
    "def _decode_record(record):\n",
    "  \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "  example = tf.parse_single_example(record, name_to_features)\n",
    "  return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/nq/natural_questions/v1.0/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a34600f3aa48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_dev_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0m_train_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_train_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_train_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".tf_record\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m train_input_fn = input_fn_builder(\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/nq/natural_questions/v1.0/train'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import run_nq\n",
    "bert_data_dir = '/data/nq/natural_questions/v1.0/'\n",
    "_train_path = '/Users/deniz/natural_questions/data/'\n",
    "_dev_path = os.path.join(bert_data_dir, 'dev')\n",
    "_train_path = os.path.join(bert_data_dir, 'train')\n",
    "train_files = [os.path.join(_train_path, _file) for _file in os.listdir(_train_path) if _file.endswith(\".tf_record\")]\n",
    "\n",
    "train_input_fn = input_fn_builder(\n",
    "  input_files=train_files,\n",
    "  seq_length=384,\n",
    "  mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=173, shape=(32, 384), dtype=int64, numpy=\n",
       "array([[  101,  2043,  2106, ...,  3237,  1022,   102],\n",
       "       [  101,  2040,  2209, ..., 11411,  9358,   102],\n",
       "       [  101,  2073,  2515, ...,  1998,  6887,   102],\n",
       "       ...,\n",
       "       [  101,  2040,  6369, ...,  1005,  1005,   102],\n",
       "       [  101,  2040,  2001, ...,  8884,  2000,   102],\n",
       "       [  101,  2029,  1997, ...,  2086,  1010,   102]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "dt = tf.data.TFRecordDataset(train_files)\n",
    "dt = dt.map(_decode_record, num_parallel_calls=10)\n",
    "dt = dt.shuffle(buffer_size=100)\n",
    "dt = dt.batch(32)\n",
    "it = dt.make_one_shot_iterator()\n",
    "a = it.get_next()\n",
    "a['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=116, shape=(32,), dtype=int64, numpy=\n",
       "array([283,   0, 148,   0,   0, 290, 229,   0,  34, 162,   0,   0,  28,\n",
       "       101, 150,   0, 155,   0,   0,  27,   0,  48, 100, 304, 209,   0,\n",
       "       212,   0,   0, 131,  87,   0])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['start_positions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=111, shape=(32,), dtype=int64, numpy=\n",
       "array([341,   0, 151,   0,   0, 299, 243,   0,  43, 171,   0,   0,  47,\n",
       "       115, 152,   0, 155,   0,   0,  85,   0,  98, 101, 354, 321,   0,\n",
       "       212,   0,   0, 244,  93,   0])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['end_positions']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/home/deniz/repos/natural_questions/model/training', '_tf_random_seed': None, '_save_summary_steps': 50, '_save_checkpoints_steps': 10, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f26bc44e278>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "######### INFERENCE    ######\n",
    "#############################\n",
    "\n",
    "from run_nq import input_fn_builder\n",
    "bert_data_dir = '/data/nq/natural_questions/v1.0/'\n",
    "from bert import modeling\n",
    "from run_nq import model_fn_builder\n",
    "# prediction\n",
    "bert_config = modeling.BertConfig.from_json_file('model/uncased_L-12_H-768_A-12/bert_config.json')\n",
    "\n",
    "_dev_path = os.path.join(bert_data_dir, 'dev')\n",
    "_train_path = os.path.join(bert_data_dir, 'train')\n",
    "_predict_path = os.path.join(bert_data_dir, 'predict')\n",
    "\n",
    "config = tf.estimator.RunConfig(\n",
    "  save_checkpoints_steps=10, # this also sets when eval starts\n",
    "  save_summary_steps=50,\n",
    "  keep_checkpoint_max=10, #train_and_eval does not save the best models, but the most recent ones.\n",
    "  model_dir='/home/deniz/repos/natural_questions/model/training'\n",
    ")\n",
    "\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "  bert_config=bert_config,\n",
    "  init_checkpoint='/home/deniz/repos/natural_questions/model/training',\n",
    "  learning_rate=1e-5,\n",
    "  num_train_steps=10,\n",
    "  num_warmup_steps=0,\n",
    "  use_tpu=False,\n",
    "  use_one_hot_embeddings=False)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=config,\n",
    "  params={'batch_size':8})\n",
    "\n",
    "\n",
    "predict_files = [os.path.join(_train_path, _file) for _file in os.listdir(_train_path) if\n",
    "                 _file.endswith(\".tf_record\")]\n",
    "predict_input_fn = input_fn_builder(\n",
    "    input_files=predict_files,\n",
    "    seq_length=384,\n",
    "    is_training=False,\n",
    "    mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Estimator.predict at 0x7f26bc43ef10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_result = estimator.predict(predict_input_fn)\n",
    "batch_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_batch_result = next(batch_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 342)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(_batch_result['y_pred_start']), np.argmax(_batch_result['y_pred_end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295, 306)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GROUND TRUTH\n",
    "_batch_result['start_positions'], _batch_result['end_positions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.176463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>295</td>\n",
       "      <td>2.008699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>298</td>\n",
       "      <td>3.161665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299</td>\n",
       "      <td>4.229423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302</td>\n",
       "      <td>0.544027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1\n",
       "0    0  0.176463\n",
       "1  295  2.008699\n",
       "2  298  3.161665\n",
       "3  299  4.229423\n",
       "4  302  0.544027"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits = pd.DataFrame([(i, score) for i, score in enumerate(_batch_result['start_logits']) if score > 0 ])\n",
    "start_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.770081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>306</td>\n",
       "      <td>6.001465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>325</td>\n",
       "      <td>0.931091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>335</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>356</td>\n",
       "      <td>0.244597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>357</td>\n",
       "      <td>2.219360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1\n",
       "0    0  0.770081\n",
       "1  306  6.001465\n",
       "2  325  0.931091\n",
       "3  335  0.933333\n",
       "4  356  0.244597\n",
       "5  357  2.219360"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_logits = pd.DataFrame([(i, score) for i, score in enumerate(_batch_result['end_logits']) if score > 0 ])\n",
    "end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.061153622438558e-09"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#####accuracy metric#####\n",
    "#########################\n",
    "\n",
    "tf.reset_default_graph()\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import metrics\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    start_ix = tf.expand_dims(tf.constant([10,20,30,40,50]),1)\n",
    "    end_ix =  tf.expand_dims(tf.constant([10,20,30,40,50]),1)\n",
    "    start_positions = tf.expand_dims(tf.constant([10,20,30,40,50]),1)\n",
    "    end_positions = tf.expand_dims(tf.constant([10,20,30,40,60]),1) #80% accuracy\n",
    "\n",
    "    y_pred = tf.concat([start_ix, end_ix], axis=-1) #[batch_size, 2]\n",
    "    y_true = tf.concat([start_positions, end_positions], axis=-1) #[batch_size, 2]\n",
    "    acc = tf.reduce_all(math_ops.equal(y_true, y_pred), axis=-1)\n",
    "    is_correct = math_ops.to_float(acc)\n",
    "    a,b = metrics.mean(is_correct)\n",
    "    \n",
    "    \n",
    "    running_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES)\n",
    "    running_vars_initializer = tf.variables_initializer(var_list=running_vars)\n",
    "    \n",
    "    sess.run(running_vars_initializer)\n",
    "    \n",
    "    # initial op\n",
    "    a_out = sess.run(a)\n",
    "    # update op\n",
    "    b_out = sess.run(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_out, b_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from preprocessing.preprocessing import *\n",
    "from run_nq import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_data_dir = \"/data/nq/natural_questions/v1.0/sample_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_files = [_file for _file in os.listdir(bert_data_dir) if _file.endswith(\".tf_record\")]\n",
    "_file_path = [os.path.join(bert_data_dir, _file) for _file in train_files]\n",
    "[tf.gfile.MakeDirs(_dir) for _dir in [_train_path, _dev_path]]\n",
    "print(_file_path)\n",
    "train_input_fn = input_fn_builder(\n",
    "    input_file=_file_path,\n",
    "    seq_length=512,\n",
    "    is_training=True,\n",
    "    drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['batch_size'] = 32\n",
    "_iter = train_input_fn(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_iter = _iter.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = _iter.get_next()\n",
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt['document_tokens'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = convert_examples_to_features(dt, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer\n",
    "if outputs:\n",
    "    print(outputs[0].targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{i: t for i, t in enumerate(outputs[0].tokens) if i >= outputs[0].targets[0][0] and i <= outputs[0].targets[0][1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_answer_start = dt['annotations'][0]['short_answers'][0]['start_byte']\n",
    "short_answer_end = dt['annotations'][0]['short_answers'][0]['end_byte']\n",
    "[t for t in dt['document_tokens'] if t['start_byte'] >= short_answer_start and t['end_byte'] <= short_answer_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_answer_start = dt['annotations'][0]['long_answer']['start_byte']\n",
    "long_answer_end = dt['annotations'][0]['long_answer']['end_byte']\n",
    "end = dt['annotations'][0]['long_answer']['end_token']+1\n",
    "start = dt['annotations'][0]['long_answer']['start_token']\n",
    "dt['document_tokens'][start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['document_tokens'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set([t['token'] for dt in data for t in dt['document_tokens'] if t['html_token']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(dt['document_html']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt['long_answer_candidates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['question_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = dt['document_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[token for token in tokens if token['start_byte'] >= start_byte_ix and token['end_byte'] <= end_byte_ix]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3tf",
   "language": "python",
   "name": "py3tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
