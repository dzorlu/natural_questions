{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import hashlib\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "from tensorflow.metrics import accuracy\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_nq import input_fn_builder\n",
    "seq_length=512\n",
    "\n",
    "name_to_features = {\n",
    "  \"input_ids\": tf.FixedLenFeature([], tf.int64),\n",
    "  \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "  \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "  \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "  \"start_bytes\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "  \"end_bytes\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "}\n",
    "name_to_features[\"start_positions\"] = tf.FixedLenFeature([], tf.int64)\n",
    "name_to_features[\"end_positions\"] = tf.FixedLenFeature([], tf.int64)\n",
    "\n",
    "def _decode_record(record):\n",
    "  \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "  example = tf.parse_single_example(record, name_to_features)\n",
    "  return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "bert_data_dir = '/Users/deniz/natural_questions/data/'\n",
    "_dev_path = os.path.join(bert_data_dir, 'dev')\n",
    "_train_path = os.path.join(bert_data_dir, 'train')\n",
    "train_files = [os.path.join(_train_path, _file) for _file in os.listdir(_train_path) if _file.endswith(\".tf_record\")]\n",
    "\n",
    "train_input_fn = input_fn_builder(\n",
    "  input_files=train_files,\n",
    "  seq_length=512,\n",
    "  is_training=True,\n",
    "  mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "dt = tf.data.TFRecordDataset(train_files)\n",
    "dt = dt.map(_decode_record, num_parallel_calls=10)\n",
    "dt = dt.shuffle(buffer_size=100)\n",
    "dt = dt.batch(32)\n",
    "it = dt.make_one_shot_iterator()\n",
    "a = it.get_next()\n",
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 3)\n",
      "(1, 2, 1)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Add as input #0(zero-based) was expected to be a int32 tensor but is a float tensor [Op:Add] name: add/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-60b3ee87aa3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3tf/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    322\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3tf/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Add as input #0(zero-based) was expected to be a int32 tensor but is a float tensor [Op:Add] name: add/"
     ]
    }
   ],
   "source": [
    "# context\n",
    "a = tf.constant([[2,10],[3,20],[4,50]])\n",
    "a = tf.constant([[0.2,0.5,0.3]])\n",
    "a = tf.expand_dims(a,1)\n",
    "print(a.shape)\n",
    "b = tf.constant([[1,2],[10,20],[1,2]])\n",
    "b = tf.constant([[1,2]])\n",
    "b = tf.expand_dims(b,2)\n",
    "print(b.shape)\n",
    "c = a + b\n",
    "out = c.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[0.2, 0.5, 0.3],[0.8, 0.05, 0.15],[0.3, 0.4, 0.3]])\n",
    "b = tf.constant([[0.1, 0.8, 0.1],[0.2, 0.5, 0.3],[0.3, 0.35, 0.35]])\n",
    "# a = tf.constant([[0.2, 0.5, 0.3]])\n",
    "# b = tf.constant([[0.1, 0.8, 0.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=467, shape=(3, 3, 3), dtype=float32, numpy=\n",
       "array([[[0.02      , 0.05      , 0.03      ],\n",
       "        [0.16000001, 0.4       , 0.24000001],\n",
       "        [0.02      , 0.05      , 0.03      ]],\n",
       "\n",
       "       [[0.16000001, 0.01      , 0.03      ],\n",
       "        [0.4       , 0.025     , 0.075     ],\n",
       "        [0.24000001, 0.015     , 0.045     ]],\n",
       "\n",
       "       [[0.09      , 0.12      , 0.09      ],\n",
       "        [0.105     , 0.14      , 0.105     ],\n",
       "        [0.105     , 0.14      , 0.105     ]]], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits = tf.expand_dims(a, 1)\n",
    "end_logits = tf.expand_dims(b,-1)\n",
    "logits = start_logits * end_logits\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax_2d(start_logits, end_logits):\n",
    "  start_logits = tf.expand_dims(start_logits, 1)\n",
    "  end_logits = tf.expand_dims(end_logits,-1)\n",
    "  logits = start_logits * end_logits\n",
    "  flat_logits = tf.reshape(logits, shape=[tf.shape(logits)[0], -1])\n",
    "  _argmax = tf.cast(tf.argmax(flat_logits, axis=-1), dtype=tf.int32)\n",
    "  return _argmax % tf.shape(logits)[1], _argmax // tf.shape(logits)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=518, shape=(3,), dtype=int32, numpy=array([1, 0, 1], dtype=int32)>,\n",
       " <tf.Tensor: id=524, shape=(3,), dtype=int32, numpy=array([1, 1, 1], dtype=int32)>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax_2d(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-395fa3c03f21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#np.argmax(d,axis=[0,1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "#np.argmax(d,axis=[0,1])\n",
    "d.argmax(axis=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax_2d(tensor):\n",
    "\n",
    "  # input format: BxHxWxD\n",
    "  assert rank(tensor) == 4\n",
    "\n",
    "  # flatten the Tensor along the height and width axes\n",
    "  flat_tensor = tf.reshape(tensor, (tf.shape(tensor)[0], -1, tf.shape(tensor)[3]))\n",
    "\n",
    "  # argmax of the flat tensor\n",
    "  argmax = tf.cast(tf.argmax(flat_tensor, axis=1), tf.int32)\n",
    "\n",
    "  # convert indexes into 2D coordinates\n",
    "  argmax_x = argmax // tf.shape(tensor)[2]\n",
    "  argmax_y = argmax % tf.shape(tensor)[2]\n",
    "\n",
    "  # stack and return 2D coordinates\n",
    "  return tf.stack((argmax_x, argmax_y), axis=1)\n",
    "\n",
    "def rank(tensor):\n",
    "\n",
    "  # return the rank of a Tensor\n",
    "  return len(tensor.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=84, shape=(1, 2, 1), dtype=int32, numpy=\n",
       "array([[[0],\n",
       "        [1]]], dtype=int32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax_2d(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gather(tensor, indices):\n",
    "  \"\"\"Gather in batch from a tensor of arbitrary size.\n",
    "\n",
    "  In pseudocode this module will produce the following:\n",
    "  output[i] = tf.gather(tensor[i], indices[i])\n",
    "\n",
    "  Args:\n",
    "    tensor: Tensor of arbitrary size.\n",
    "    indices: Vector of indices.\n",
    "  Returns:\n",
    "    output: A tensor of gathered values.\n",
    "  \"\"\"\n",
    "  shape = get_shape(tensor)\n",
    "  flat_first = tf.reshape(tensor, [shape[0] * shape[1]] + shape[2:])\n",
    "  indices = tf.convert_to_tensor(indices)\n",
    "  offset_shape = [shape[0]] + [1] * (indices.shape.ndims - 1)\n",
    "  offset = tf.reshape(tf.range(shape[0]) * shape[1], offset_shape)\n",
    "  output = tf.gather(flat_first, indices + offset)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#####accuracy metric#####\n",
    "#########################\n",
    "\n",
    "tf.reset_default_graph()\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import metrics\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    start_ix = tf.expand_dims(tf.constant([10,20,30,40,50]),1)\n",
    "    end_ix =  tf.expand_dims(tf.constant([10,20,30,40,50]),1)\n",
    "    start_positions = tf.expand_dims(tf.constant([10,20,30,40,50]),1)\n",
    "    end_positions = tf.expand_dims(tf.constant([10,20,30,40,60]),1) #80% accuracy\n",
    "\n",
    "    y_pred = tf.concat([start_ix, end_ix], axis=-1) #[batch_size, 2]\n",
    "    y_true = tf.concat([start_positions, end_positions], axis=-1) #[batch_size, 2]\n",
    "    acc = tf.reduce_all(math_ops.equal(y_true, y_pred), axis=-1)\n",
    "    is_correct = math_ops.to_float(acc)\n",
    "    a,b = metrics.mean(is_correct)\n",
    "    \n",
    "    \n",
    "    running_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES)\n",
    "    running_vars_initializer = tf.variables_initializer(var_list=running_vars)\n",
    "    \n",
    "    sess.run(running_vars_initializer)\n",
    "    \n",
    "    # initial op\n",
    "    a_out = sess.run(a)\n",
    "    # update op\n",
    "    b_out = sess.run(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_out, b_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from preprocessing.preprocessing import *\n",
    "from run_nq import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_data_dir = \"/data/nq/natural_questions/v1.0/sample_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_files = [_file for _file in os.listdir(bert_data_dir) if _file.endswith(\".tf_record\")]\n",
    "_file_path = [os.path.join(bert_data_dir, _file) for _file in train_files]\n",
    "[tf.gfile.MakeDirs(_dir) for _dir in [_train_path, _dev_path]]\n",
    "print(_file_path)\n",
    "train_input_fn = input_fn_builder(\n",
    "    input_file=_file_path,\n",
    "    seq_length=512,\n",
    "    is_training=True,\n",
    "    drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['batch_size'] = 32\n",
    "_iter = train_input_fn(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_iter = _iter.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = _iter.get_next()\n",
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                                  tokenization_info[\"do_lower_case\"]])\n",
    "\n",
    "    return bert.tokenization.FullTokenizer(\n",
    "        vocab_file=vocab_file, do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = data[-110]\n",
    "dt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['question_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt['document_tokens'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = convert_examples_to_features(dt, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer\n",
    "if outputs:\n",
    "    print(outputs[0].targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{i: t for i, t in enumerate(outputs[0].tokens) if i >= outputs[0].targets[0][0] and i <= outputs[0].targets[0][1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_answer_start = dt['annotations'][0]['short_answers'][0]['start_byte']\n",
    "short_answer_end = dt['annotations'][0]['short_answers'][0]['end_byte']\n",
    "[t for t in dt['document_tokens'] if t['start_byte'] >= short_answer_start and t['end_byte'] <= short_answer_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_answer_start = dt['annotations'][0]['long_answer']['start_byte']\n",
    "long_answer_end = dt['annotations'][0]['long_answer']['end_byte']\n",
    "end = dt['annotations'][0]['long_answer']['end_token']+1\n",
    "start = dt['annotations'][0]['long_answer']['start_token']\n",
    "dt['document_tokens'][start:end]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Wordpiece\n",
    "1 - wordpiece the 'document_tokens' (remove html?)\n",
    "2 - rearrrange long and short answer byte indices accordingly.\n",
    "3 - above logic re-produces the entire text, which is too large. need to do\n",
    "    ([CLS], tokenized question, [SEP], token from content, [SEP].) -> 512 dimensions\n",
    "    \n",
    "the paper only collects short spans but falls back to long span if short span is not available. \n",
    "take examples where both short **and** long exists\n",
    "(35% of the dataset. another 37% where long answer is not available but good question.)\n",
    "\n",
    "------------------\n",
    "for each doc:\n",
    "    wordpiece the question. determine the span. this is dimensions minus the question minus special chars.\n",
    "    wordpiece the 'document_tokens' (remove html?)\n",
    "    rearrrange long and short answer byte indices accordingly.\n",
    "    \n",
    "    for each span:\n",
    "        slide the window. determine if short answer / long answer (?) is contained in the span.\n",
    "        could be multiple short answers.\n",
    "        adjust the ix accordingly. if not mark is as null / [CLS]?\n",
    "    downsample null instances\n",
    "    dump json\n",
    "    \n",
    "-------------------\n",
    "how do you train on both long and short answers? the paper emits short answers and relies on DOM to extract long answers. \n",
    "In addition, at inference time, the authors change the answers to **long only** or **no answers** based on QA eval script. \n",
    "\n",
    "long answer must be within a HTML bounding box (a paragraph or a table).\\\n",
    "\n",
    "document-QA, which is a baseline, makes a prediction but whether the prediction is long or short is determined by the inclusion of start / end of passage tokens.\n",
    "\n",
    "whether long answer exists is determined by the threshold.\n",
    "or in document-qa. predict. if the span goes over a passage, that is the long answers. and short answer does not exist?\n",
    "\n",
    "a single answer to predict on. if short answer, use. if long answer, use thsat. \n",
    "\n",
    "long answer only: 13%\n",
    "long and short: 35%\n",
    "\n",
    "\n",
    "--------------------\n",
    "how do i do it multithreaded? dask\n",
    "--------------------\n",
    "BERT: question has a positional embedding A, and answer has B.\n",
    "\n",
    "--------------------\n",
    "need to prredict if the answer is NULL. done through some post-processing heuristics on eval script score cutoff?\n",
    "\n",
    "--------------------\n",
    "what is a score.\n",
    "\n",
    "--------------------\n",
    "preprocessing should take something like a dict of labels and map them onto the new. this will apply to both problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['document_tokens'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set([t['token'] for dt in data for t in dt['document_tokens'] if t['html_token']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(dt['document_html']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt['long_answer_candidates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['question_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_byte_ix = dt['annotations'][0]['short_answers'][0]['end_byte']\n",
    "start_byte_ix = dt['annotations'][0]['short_answers'][0]['start_byte']\n",
    "start_byte_ix, end_byte_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = dt['document_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[token for token in tokens if token['start_byte'] >= start_byte_ix and token['end_byte'] <= end_byte_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_byte_ix_long = dt['annotations'][0]['long_answer']['end_byte']\n",
    "start_byte_ix_long = dt['annotations'][0]['long_answer']['start_byte']\n",
    "start_byte_ix_long, end_byte_ix_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' '.join([token['token'] for token in tokens if token['start_byte'] >= start_byte_ix_long and token['end_byte'] <= end_byte_ix_long and not token['html_token']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_contains_short = 0\n",
    "short = []\n",
    "only_long = []\n",
    "nb_short_answers = []\n",
    "yes_no_answers = []\n",
    "multiple_short_answers_q = []\n",
    "for dt in data:\n",
    "    if dt['annotations'][0]['yes_no_answer'] != 'NONE':\n",
    "        yes_no_answers.append(dt)\n",
    "    short_answers = dt['annotations'][0]['short_answers']\n",
    "    if short_answers:\n",
    "        if len(short_answers) > 1:\n",
    "            multiple_short_answers_q.append(dt)\n",
    "        \n",
    "        end_byte_ix = short_answers[0]['end_byte']\n",
    "        start_byte_ix = short_answers[0]['start_byte']\n",
    "        end_byte_ix_long = dt['annotations'][0]['long_answer']['end_byte']\n",
    "        start_byte_ix_long = dt['annotations'][0]['long_answer']['start_byte']\n",
    "        short.append(dt)  \n",
    "    else:\n",
    "        only_long.append(dt) \n",
    "print(len(only_long))\n",
    "print(len(short))\n",
    "print(len(multiple_short_answers_q))\n",
    "print(len(yes_no_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_no_answers[0]['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_short_answers_q[0]['annotations'][0]['short_answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_long[0]['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#display(HTML(multiple_short_answers_q['document_html']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['long_answer_candidates'][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = only_long[1]\n",
    "end_byte_ix_long = dt['annotations'][0]['long_answer']['end_byte']\n",
    "start_byte_ix_long = dt['annotations'][0]['long_answer']['start_byte']\n",
    "dt['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = dt['document_tokens']\n",
    "' '.join([token['token'] for token in tokens if token['start_byte'] >= start_byte_ix_long and token['end_byte'] <= end_byte_ix_long and not token['html_token']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt['question_text'])\n",
    "#display(HTML(dt['document_html']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpuenv",
   "language": "python",
   "name": "tensorflow_gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
