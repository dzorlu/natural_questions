{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "# from bert import run_classifier\n",
    "# from bert import optimization\n",
    "from bert import tokenization\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import os\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "from tensorflow.metrics import accuracy\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax_2d(start_l, end_l):\n",
    "    #TODO: Fix the score.\n",
    "    \"\"\"\n",
    "    argmax over start and end logits\n",
    "    :param start_l:\n",
    "    :param end_l:\n",
    "    :return: score, [batch_size, 2]\n",
    "    \"\"\"\n",
    "    start_l = tf.expand_dims(start_l, 1)\n",
    "    end_l = tf.expand_dims(end_l, -1)\n",
    "    logits = start_l * end_l\n",
    "    flat_logits = tf.reshape(logits, shape=[tf.shape(logits)[0], -1])\n",
    "    _argmax = tf.cast(tf.argmax(flat_logits, axis=-1), dtype=tf.int32)\n",
    "    ix = tf.cast(tf.stack([_argmax % tf.shape(logits)[1], _argmax // tf.shape(logits)[2]], axis=-1), dtype=tf.int64)\n",
    "    return tf.cast(tf.reduce_max(logits, axis=-1), tf.int64), ix\n",
    "\n",
    "\n",
    "def span_accuracy(start_logits, end_logits, start_positions, end_positions):\n",
    "    \"\"\"\n",
    "    Exact span match.\n",
    "        pred -> [10,20] gt -> [10,20] : True\n",
    "        pred -> [10,20] gt -> [10,15] : False\n",
    "    :param start_logits: [batch_size, seq_length]\n",
    "    :param end_logits: [batch_size, seq_length]\n",
    "    :param start_positions: [batch_size]\n",
    "    :param end_positions: [batch_size]\n",
    "    :return: a tuple of:\n",
    "        accuracy: A `Tensor` representing the accuracy, the value of `total` divided\n",
    "          by `count`.\n",
    "        update_op: An operation that increments the `total` and `count` variables\n",
    "          appropriately and whose value matches `accuracy`.\n",
    "    \"\"\"\n",
    "\n",
    "    _, y_pred_ix = argmax_2d(start_logits, end_logits)\n",
    "    start_positions = tf.expand_dims(start_positions, axis=-1)\n",
    "    end_positions = tf.expand_dims(end_positions, axis=-1)\n",
    "    y_true_ix = tf.concat([start_positions, end_positions], axis=-1)  # [batch_size, 2]\n",
    "    diff = y_true_ix - y_pred_ix\n",
    "    # difference between prediction and true_ix for debudding purposes.\n",
    "    tf.summary.histogram('start_diff', diff[:, 0])\n",
    "    tf.summary.histogram('end_diff', diff[:, 1])\n",
    "    acc = tf.reduce_all(math_ops.equal(y_true_ix, y_pred_ix), axis=-1)\n",
    "    is_correct = math_ops.to_float(acc)\n",
    "    return metrics.mean(is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[0.1, 0.4, 0.5],[0.1, 0.4, 0.5],[0.1, 0.9, 0.5]])\n",
    "b = tf.constant([[0.1, 0.4, 0.5],[0.5, 0.4, 0.1],[0.1, 0.9, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=160, shape=(3, 2), dtype=int64, numpy=\n",
       "array([[2, 2],\n",
       "       [2, 0],\n",
       "       [1, 1]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, y_pred_ix = argmax_2d(a,b)\n",
    "y_pred_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=174, shape=(3, 2), dtype=int64, numpy=\n",
       "array([[2, 2],\n",
       "       [2, 0],\n",
       "       [0, 1]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_positions = tf.cast(tf.constant([2,2,0]), dtype=tf.int64)\n",
    "end_positions = tf.cast(tf.constant([2,0,1]), dtype=tf.int64)\n",
    "start_positions = tf.expand_dims(start_positions, axis=-1)\n",
    "end_positions = tf.expand_dims(end_positions, axis=-1)\n",
    "y_true_ix = tf.concat([start_positions, end_positions], axis=-1)  # [batch_size, 2]\n",
    "y_true_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=183, shape=(3,), dtype=float32, numpy=array([1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = tf.reduce_all(math_ops.equal(y_true_ix, y_pred_ix), axis=-1)\n",
    "is_correct = math_ops.to_float(acc)\n",
    "is_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing the preprocessing module\n",
    "\n",
    "from preprocessing.preprocessing import convert_example\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                                  tokenization_info[\"do_lower_case\"]])\n",
    "\n",
    "    return bert.tokenization.FullTokenizer(\n",
    "        vocab_file=vocab_file, do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1'.\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1: 31.62MB\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-91e602849f71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_tokenizer_from_hub_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-7c16fcad1454>\u001b[0m in \u001b[0;36mcreate_tokenizer_from_hub_module\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mbert_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBERT_MODEL_HUB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mtokenization_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tokenization_info\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, spec, trainable, name, tags)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \"\"\"\n\u001b[1;32m    143\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_module_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36mas_module_spec\u001b[0;34m(spec)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_module_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown module spec type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36mload_module_spec\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mon\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mhandling\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m   \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/tensorflow_hub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     raise RuntimeError(\n\u001b[1;32m     44\u001b[0m         \"Missing implementation that supports: %s(*%r, **%r)\" % (\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/tensorflow_hub/compressed_module_resolver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, handle)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     return resolver.atomic_download(handle, download, module_dir,\n\u001b[0;32m--> 102\u001b[0;31m                                     self._lock_file_timeout_sec())\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_lock_file_timeout_sec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/tensorflow_hub/resolver.py\u001b[0m in \u001b[0;36matomic_download\u001b[0;34m(handle, download_fn, module_dir, lock_file_timeout_sec)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading TF-Hub Module '%s'.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m     \u001b[0mdownload_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m     \u001b[0;31m# Write module descriptor to capture information about which module was\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;31m# downloaded by whom and when. The file stored at the same level as a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/tensorflow_hub/compressed_module_resolver.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(handle, tmp_dir)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl_opener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m       return resolver.DownloadManager(cur_url).download_and_uncompress(\n\u001b[0;32m---> 99\u001b[0;31m           response, tmp_dir)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     return resolver.atomic_download(handle, download, module_dir,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/tensorflow_hub/resolver.py\u001b[0m in \u001b[0;36mdownload_and_uncompress\u001b[0;34m(self, fileobj, dst_path)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_target_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m           \u001b[0;32melif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_target_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/site-packages/tensorflow_hub/resolver.py\u001b[0m in \u001b[0;36m_extract_file\u001b[0;34m(self, tgz, tarinfo, dst_path, buffer_size)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m       \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected end of data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36m__read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1007\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1009\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "token = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/Users/deniz/natural_questions/data/v1.0_sample_nq-train-sample.jsonl:0\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(276, 279)\n",
      "INFO:tensorflow:(148, 151)\n",
      "INFO:tensorflow:(20, 23)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(253, 302)\n",
      "INFO:tensorflow:(125, 174)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(40, 316)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(327, 332)\n",
      "INFO:tensorflow:(199, 204)\n",
      "INFO:tensorflow:(71, 76)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(314, 315)\n",
      "INFO:tensorflow:(186, 187)\n",
      "INFO:tensorflow:(58, 59)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(370, 370)\n",
      "INFO:tensorflow:(242, 242)\n",
      "INFO:tensorflow:(114, 114)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(202, 322)\n",
      "INFO:tensorflow:(74, 194)\n",
      "INFO:tensorflow:(249, 257)\n",
      "INFO:tensorflow:(121, 129)\n",
      "INFO:tensorflow:(205, 316)\n",
      "INFO:tensorflow:(77, 188)\n",
      "INFO:tensorflow:(140, 285)\n",
      "INFO:tensorflow:(12, 157)\n",
      "INFO:tensorflow:(253, 299)\n",
      "INFO:tensorflow:(125, 171)\n",
      "INFO:tensorflow:(244, 268)\n",
      "INFO:tensorflow:(116, 140)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(87, 95)\n",
      "INFO:tensorflow:(150, 267)\n",
      "INFO:tensorflow:(22, 139)\n",
      "INFO:tensorflow:(337, 337)\n",
      "INFO:tensorflow:(209, 209)\n",
      "INFO:tensorflow:(81, 81)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(170, 189)\n",
      "INFO:tensorflow:(42, 61)\n",
      "INFO:tensorflow:(179, 183)\n",
      "INFO:tensorflow:(51, 55)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(292, 295)\n",
      "INFO:tensorflow:(164, 167)\n",
      "INFO:tensorflow:(36, 39)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(56, 377)\n",
      "INFO:tensorflow:(258, 258)\n",
      "INFO:tensorflow:(130, 130)\n",
      "INFO:tensorflow:(135, 139)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(37, 66)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(36, 37)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(125, 225)\n",
      "INFO:tensorflow:(149, 153)\n",
      "INFO:tensorflow:(21, 25)\n",
      "INFO:tensorflow:(303, 309)\n",
      "INFO:tensorflow:(175, 181)\n",
      "INFO:tensorflow:(47, 53)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(293, 293)\n",
      "INFO:tensorflow:(165, 165)\n",
      "INFO:tensorflow:(37, 37)\n",
      "INFO:tensorflow:(251, 257)\n",
      "INFO:tensorflow:(123, 129)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(241, 245)\n",
      "INFO:tensorflow:(113, 117)\n",
      "INFO:tensorflow:(290, 292)\n",
      "INFO:tensorflow:(162, 164)\n",
      "INFO:tensorflow:(34, 36)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(230, 232)\n",
      "INFO:tensorflow:(102, 104)\n",
      "INFO:tensorflow:(269, 272)\n",
      "INFO:tensorflow:(141, 144)\n",
      "INFO:tensorflow:(13, 16)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(296, 361)\n",
      "INFO:tensorflow:(168, 233)\n",
      "INFO:tensorflow:(40, 105)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(95, 98)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(227, 231)\n",
      "INFO:tensorflow:(99, 103)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(119, 206)\n",
      "INFO:tensorflow:(111, 113)\n",
      "INFO:tensorflow:(170, 171)\n",
      "INFO:tensorflow:(42, 43)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(108, 111)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(310, 330)\n",
      "INFO:tensorflow:(182, 202)\n",
      "INFO:tensorflow:(54, 74)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(354, 354)\n",
      "INFO:tensorflow:(226, 226)\n",
      "INFO:tensorflow:(98, 98)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(216, 218)\n",
      "INFO:tensorflow:(88, 90)\n",
      "INFO:tensorflow:(313, 315)\n",
      "INFO:tensorflow:(185, 187)\n",
      "INFO:tensorflow:(57, 59)\n",
      "INFO:tensorflow:(191, 235)\n",
      "INFO:tensorflow:(63, 107)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(67, 68)\n",
      "INFO:tensorflow:(263, 264)\n",
      "INFO:tensorflow:(135, 136)\n",
      "INFO:tensorflow:(44, 53)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(333, 333)\n",
      "INFO:tensorflow:(205, 205)\n",
      "INFO:tensorflow:(77, 77)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(99, 101)\n",
      "INFO:tensorflow:(218, 356)\n",
      "INFO:tensorflow:(90, 228)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(375, 378)\n",
      "INFO:tensorflow:(247, 250)\n",
      "INFO:tensorflow:(119, 122)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(184, 193)\n",
      "INFO:tensorflow:(56, 65)\n",
      "INFO:tensorflow:(23, 103)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(228, 356)\n",
      "INFO:tensorflow:(100, 228)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(94, 205)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(98, 354)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(237, 239)\n",
      "INFO:tensorflow:(109, 111)\n",
      "INFO:tensorflow:(129, 138)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(158, 161)\n",
      "INFO:tensorflow:(30, 33)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(300, 327)\n",
      "INFO:tensorflow:(172, 199)\n",
      "INFO:tensorflow:(44, 71)\n",
      "INFO:tensorflow:(267, 268)\n",
      "INFO:tensorflow:(139, 140)\n",
      "INFO:tensorflow:(11, 12)\n",
      "INFO:tensorflow:(151, 273)\n",
      "INFO:tensorflow:(23, 145)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(191, 364)\n",
      "INFO:tensorflow:(63, 236)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(50, 55)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(286, 289)\n",
      "INFO:tensorflow:(158, 161)\n",
      "INFO:tensorflow:(30, 33)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(174, 316)\n",
      "INFO:tensorflow:(46, 188)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(133, 235)\n",
      "INFO:tensorflow:(121, 122)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(262, 262)\n",
      "INFO:tensorflow:(134, 134)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(150, 263)\n",
      "INFO:tensorflow:(22, 135)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(123, 124)\n",
      "INFO:tensorflow:(316, 316)\n",
      "INFO:tensorflow:(188, 188)\n",
      "INFO:tensorflow:(60, 60)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(323, 325)\n",
      "INFO:tensorflow:(195, 197)\n",
      "INFO:tensorflow:(67, 69)\n",
      "INFO:tensorflow:(181, 183)\n",
      "INFO:tensorflow:(53, 55)\n",
      "INFO:tensorflow:(215, 353)\n",
      "INFO:tensorflow:(87, 225)\n",
      "INFO:tensorflow:(134, 136)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(288, 288)\n",
      "INFO:tensorflow:(160, 160)\n",
      "INFO:tensorflow:(32, 32)\n",
      "INFO:tensorflow:(138, 139)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(229, 243)\n",
      "INFO:tensorflow:(101, 115)\n",
      "INFO:tensorflow:(19, 292)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(263, 264)\n",
      "INFO:tensorflow:(135, 136)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(94, 354)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(227, 342)\n",
      "INFO:tensorflow:(99, 214)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(322, 325)\n",
      "INFO:tensorflow:(194, 197)\n",
      "INFO:tensorflow:(66, 69)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(346, 347)\n",
      "INFO:tensorflow:(218, 219)\n",
      "INFO:tensorflow:(90, 91)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(212, 357)\n",
      "INFO:tensorflow:(84, 229)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(236, 258)\n",
      "INFO:tensorflow:(108, 130)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(249, 253)\n",
      "INFO:tensorflow:(121, 125)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(145, 300)\n",
      "INFO:tensorflow:(17, 172)\n",
      "INFO:tensorflow:(137, 320)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(150, 152)\n",
      "INFO:tensorflow:(22, 24)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(267, 270)\n",
      "INFO:tensorflow:(139, 142)\n",
      "INFO:tensorflow:(11, 14)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(254, 258)\n",
      "INFO:tensorflow:(126, 130)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(379, 380)\n",
      "INFO:tensorflow:(251, 252)\n",
      "INFO:tensorflow:(123, 124)\n",
      "INFO:tensorflow:(80, 81)\n",
      "INFO:tensorflow:(286, 296)\n",
      "INFO:tensorflow:(158, 168)\n",
      "INFO:tensorflow:(30, 40)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(172, 311)\n",
      "INFO:tensorflow:(44, 183)\n",
      "INFO:tensorflow:(372, 377)\n",
      "INFO:tensorflow:(244, 249)\n",
      "INFO:tensorflow:(116, 121)\n",
      "INFO:tensorflow:(0, 0)\n",
      "INFO:tensorflow:(0, 0)\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "_train_file = '/Users/deniz/natural_questions/data/v1.0_sample_nq-train-sample.jsonl'\n",
    "with jsonlines.open(_train_file) as reader:\n",
    "    features, examples = [], []\n",
    "    for i, example in enumerate(reader):\n",
    "        if i % 1e3 == 0: tf.logging.info(\"{}:{}\".format(_train_file, i))\n",
    "        examples.append(example)\n",
    "        dt = convert_example(example,\n",
    "                             features,\n",
    "                            tokenizer=token,\n",
    "                            is_training=True,\n",
    "                            max_seq_length=384,\n",
    "                        doc_stride=128,\n",
    "                        max_query_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 338)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples), len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2975172535563055798"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = features[10]\n",
    "feature.example_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(i):\n",
    "    feature = features[i]\n",
    "    example_id = feature.example_id\n",
    "    example = [x for x in examples if x['example_id'] == example_id][0]\n",
    "    return feature, example  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(example):\n",
    "    \"\"\"\n",
    "    if short, else long\n",
    "    \"\"\"\n",
    "    annotation = example['annotations'][0]\n",
    "    end_byte_ix, start_byte_ix = None, None\n",
    "    start_token, end_token = None, None\n",
    "    if annotation['short_answers']:\n",
    "        end_byte_ix = annotation['short_answers'][0]['end_byte']\n",
    "        start_token = annotation['short_answers'][0]['start_token']\n",
    "        end_token = annotation['short_answers'][0]['end_token']\n",
    "        start_byte_ix = annotation['short_answers'][0]['start_byte']\n",
    "    else:\n",
    "        end_byte_ix = annotation['long_answer']['end_byte']\n",
    "        start_byte_ix = annotation['long_answer']['start_byte']\n",
    "        start_token = annotation['long_answer']['start_token']\n",
    "        end_token = annotation['long_answer']['end_token']\n",
    "    return {'end_byte_ix': end_byte_ix, \n",
    "            'start_byte_ix': start_byte_ix,\n",
    "            'start_token': start_token,\n",
    "            'end_token': end_token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate(i):\n",
    "    # get the feature and example the feature is derived from.\n",
    "    feature, example = test(i)\n",
    "    # get the ground truth annotations.\n",
    "    gt = get_annotations(example)\n",
    "    # get start byte and end bytes for targets.\n",
    "    if feature.targets[0] == 0:\n",
    "        return (i, True)\n",
    "    start_bytes = feature.start_bytes[feature.targets[0]]\n",
    "    end_bytes = feature.end_bytes[feature.targets[1]]\n",
    "    if start_bytes == gt['start_byte_ix'] and end_bytes == gt['end_byte_ix']:\n",
    "        return (i,True)\n",
    "    else:\n",
    "        return (i, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'end_byte_ix': 96731, 'start_byte_ix': 96715, 'start_token': 3521, 'end_token': 3525}\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, True)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature, example = test(1)\n",
    "gt = get_annotations(example)\n",
    "print(gt)\n",
    "start_bytes = feature.start_bytes[feature.targets[0]]\n",
    "end_bytes = feature.end_bytes[feature.targets[1]]\n",
    "feature.targets, start_bytes, end_bytes\n",
    "_validate(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = []\n",
    "for i in range(len(features)):\n",
    "    _assertion =  _validate(i)\n",
    "    if not _assertion[1]:\n",
    "        ix.append(i)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth\n",
      "{'end_byte_ix': 55798, 'start_byte_ix': 55137, 'start_token': 893, 'end_token': 1001}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55140, 55794)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assertion fails\n",
    "feature, example = test(ix[2])\n",
    "gt = get_annotations(example)\n",
    "print('ground truth')\n",
    "print(gt)\n",
    "start_bytes = feature.start_bytes[feature.targets[0]]\n",
    "end_bytes = feature.end_bytes[feature.targets[1]]\n",
    "start_bytes, end_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'annotation_id': 13306123758205215060,\n",
       "  'long_answer': {'candidate_index': 32,\n",
       "   'end_byte': 55798,\n",
       "   'end_token': 1001,\n",
       "   'start_byte': 55137,\n",
       "   'start_token': 893},\n",
       "  'short_answers': [],\n",
       "  'yes_no_answer': 'NONE'}]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'end_byte': 55140, 'html_token': True, 'start_byte': 55137, 'token': '<P>'},\n",
       " {'end_byte': 55143, 'html_token': False, 'start_byte': 55140, 'token': 'The'},\n",
       " {'end_byte': 55153,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55144,\n",
       "  'token': 'marooning'},\n",
       " {'end_byte': 55156, 'html_token': False, 'start_byte': 55154, 'token': 'of'},\n",
       " {'end_byte': 55167,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55160,\n",
       "  'token': 'Voyager'},\n",
       " {'end_byte': 55174, 'html_token': False, 'start_byte': 55172, 'token': 'in'},\n",
       " {'end_byte': 55178, 'html_token': False, 'start_byte': 55175, 'token': 'the'},\n",
       " {'end_byte': 55184,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55179,\n",
       "  'token': 'Delta'},\n",
       " {'end_byte': 55193,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55185,\n",
       "  'token': 'Quadrant'},\n",
       " {'end_byte': 55202,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55194,\n",
       "  'token': 'provided'},\n",
       " {'end_byte': 55208,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55203,\n",
       "  'token': 'Paris'},\n",
       " {'end_byte': 55213,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55209,\n",
       "  'token': 'with'},\n",
       " {'end_byte': 55215, 'html_token': False, 'start_byte': 55214, 'token': 'a'},\n",
       " {'end_byte': 55219, 'html_token': False, 'start_byte': 55216, 'token': 'new'},\n",
       " {'end_byte': 55229,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55220,\n",
       "  'token': 'beginning'},\n",
       " {'end_byte': 55230, 'html_token': False, 'start_byte': 55229, 'token': '.'},\n",
       " {'end_byte': 55238,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55231,\n",
       "  'token': 'Janeway'},\n",
       " {'end_byte': 55243,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55239,\n",
       "  'token': 'gave'},\n",
       " {'end_byte': 55249,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55244,\n",
       "  'token': 'Paris'},\n",
       " {'end_byte': 55251, 'html_token': False, 'start_byte': 55250, 'token': 'a'},\n",
       " {'end_byte': 55257,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55252,\n",
       "  'token': 'field'},\n",
       " {'end_byte': 55268,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55258,\n",
       "  'token': 'commission'},\n",
       " {'end_byte': 55271, 'html_token': False, 'start_byte': 55269, 'token': 'as'},\n",
       " {'end_byte': 55273, 'html_token': False, 'start_byte': 55272, 'token': 'a'},\n",
       " {'end_byte': 55283,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55274,\n",
       "  'token': 'Starfleet'},\n",
       " {'end_byte': 55294,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55284,\n",
       "  'token': 'lieutenant'},\n",
       " {'end_byte': 55298, 'html_token': False, 'start_byte': 55295, 'token': 'and'},\n",
       " {'end_byte': 55303,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55299,\n",
       "  'token': 'made'},\n",
       " {'end_byte': 55307, 'html_token': False, 'start_byte': 55304, 'token': 'him'},\n",
       " {'end_byte': 55313,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55308,\n",
       "  'token': 'chief'},\n",
       " {'end_byte': 55322,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55314,\n",
       "  'token': 'helmsman'},\n",
       " {'end_byte': 55325, 'html_token': False, 'start_byte': 55323, 'token': 'of'},\n",
       " {'end_byte': 55336,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55329,\n",
       "  'token': 'Voyager'},\n",
       " {'end_byte': 55341, 'html_token': False, 'start_byte': 55340, 'token': '.'},\n",
       " {'end_byte': 55344, 'html_token': False, 'start_byte': 55342, 'token': 'He'},\n",
       " {'end_byte': 55348, 'html_token': False, 'start_byte': 55345, 'token': 'had'},\n",
       " {'end_byte': 55350, 'html_token': False, 'start_byte': 55349, 'token': 'a'},\n",
       " {'end_byte': 55356,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55351,\n",
       "  'token': 'rough'},\n",
       " {'end_byte': 55362,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55357,\n",
       "  'token': 'start'},\n",
       " {'end_byte': 55363, 'html_token': False, 'start_byte': 55362, 'token': ','},\n",
       " {'end_byte': 55371,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55364,\n",
       "  'token': 'however'},\n",
       " {'end_byte': 55372, 'html_token': False, 'start_byte': 55371, 'token': ','},\n",
       " {'end_byte': 55375, 'html_token': False, 'start_byte': 55373, 'token': 'as'},\n",
       " {'end_byte': 55385,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55376,\n",
       "  'token': 'Starfleet'},\n",
       " {'end_byte': 55389, 'html_token': False, 'start_byte': 55386, 'token': 'and'},\n",
       " {'end_byte': 55396,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55390,\n",
       "  'token': 'Maquis'},\n",
       " {'end_byte': 55402,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55397,\n",
       "  'token': 'alike'},\n",
       " {'end_byte': 55409,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55403,\n",
       "  'token': 'viewed'},\n",
       " {'end_byte': 55415,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55410,\n",
       "  'token': 'Paris'},\n",
       " {'end_byte': 55420,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55416,\n",
       "  'token': 'with'},\n",
       " {'end_byte': 55430,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55421,\n",
       "  'token': 'suspicion'},\n",
       " {'end_byte': 55431, 'html_token': False, 'start_byte': 55430, 'token': '.'},\n",
       " {'end_byte': 55437,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55432,\n",
       "  'token': 'Paris'},\n",
       " {'end_byte': 55444,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55438,\n",
       "  'token': 'worked'},\n",
       " {'end_byte': 55449,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55445,\n",
       "  'token': 'hard'},\n",
       " {'end_byte': 55452, 'html_token': False, 'start_byte': 55450, 'token': 'to'},\n",
       " {'end_byte': 55457,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55453,\n",
       "  'token': 'earn'},\n",
       " {'end_byte': 55461, 'html_token': False, 'start_byte': 55458, 'token': 'his'},\n",
       " {'end_byte': 55471,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55462,\n",
       "  'token': 'crewmates'},\n",
       " {'end_byte': 55476, 'html_token': False, 'start_byte': 55471, 'token': \"'\"},\n",
       " {'end_byte': 55484,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55477,\n",
       "  'token': 'respect'},\n",
       " {'end_byte': 55485, 'html_token': False, 'start_byte': 55484, 'token': '.'},\n",
       " {'end_byte': 55492,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55486,\n",
       "  'token': 'During'},\n",
       " {'end_byte': 55497,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55493,\n",
       "  'token': 'this'},\n",
       " {'end_byte': 55502,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55498,\n",
       "  'token': 'time'},\n",
       " {'end_byte': 55503, 'html_token': False, 'start_byte': 55502, 'token': ','},\n",
       " {'end_byte': 55506, 'html_token': False, 'start_byte': 55504, 'token': 'he'},\n",
       " {'end_byte': 55513,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55507,\n",
       "  'token': 'became'},\n",
       " {'end_byte': 55518,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55514,\n",
       "  'token': 'best'},\n",
       " {'end_byte': 55526,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55519,\n",
       "  'token': 'friends'},\n",
       " {'end_byte': 55531,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55527,\n",
       "  'token': 'with'},\n",
       " {'end_byte': 55538,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55532,\n",
       "  'token': 'Ensign'},\n",
       " {'end_byte': 55612,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55607,\n",
       "  'token': 'Harry'},\n",
       " {'end_byte': 55616, 'html_token': False, 'start_byte': 55613, 'token': 'Kim'},\n",
       " {'end_byte': 55621, 'html_token': False, 'start_byte': 55620, 'token': ','},\n",
       " {'end_byte': 55623, 'html_token': False, 'start_byte': 55622, 'token': 'a'},\n",
       " {'end_byte': 55629,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55624,\n",
       "  'token': 'young'},\n",
       " {'end_byte': 55637,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55630,\n",
       "  'token': 'officer'},\n",
       " {'end_byte': 55640, 'html_token': False, 'start_byte': 55638, 'token': 'on'},\n",
       " {'end_byte': 55644, 'html_token': False, 'start_byte': 55641, 'token': 'his'},\n",
       " {'end_byte': 55650,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55645,\n",
       "  'token': 'first'},\n",
       " {'end_byte': 55658,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55651,\n",
       "  'token': 'mission'},\n",
       " {'end_byte': 55662, 'html_token': False, 'start_byte': 55659, 'token': 'who'},\n",
       " {'end_byte': 55669,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55663,\n",
       "  'token': 'defied'},\n",
       " {'end_byte': 55673, 'html_token': False, 'start_byte': 55670, 'token': 'his'},\n",
       " {'end_byte': 55683,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55674,\n",
       "  'token': 'crewmates'},\n",
       " {'end_byte': 55686, 'html_token': False, 'start_byte': 55684, 'token': 'to'},\n",
       " {'end_byte': 55695,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55687,\n",
       "  'token': 'befriend'},\n",
       " {'end_byte': 55701,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55696,\n",
       "  'token': 'Paris'},\n",
       " {'end_byte': 55702, 'html_token': False, 'start_byte': 55701, 'token': '.'},\n",
       " {'end_byte': 55713,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55703,\n",
       "  'token': 'Eventually'},\n",
       " {'end_byte': 55714, 'html_token': False, 'start_byte': 55713, 'token': ','},\n",
       " {'end_byte': 55720,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55715,\n",
       "  'token': 'Paris'},\n",
       " {'end_byte': 55724, 'html_token': False, 'start_byte': 55721, 'token': 'was'},\n",
       " {'end_byte': 55733,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55725,\n",
       "  'token': 'accepted'},\n",
       " {'end_byte': 55736, 'html_token': False, 'start_byte': 55734, 'token': 'by'},\n",
       " {'end_byte': 55740, 'html_token': False, 'start_byte': 55737, 'token': 'the'},\n",
       " {'end_byte': 55745,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55741,\n",
       "  'token': 'crew'},\n",
       " {'end_byte': 55749, 'html_token': False, 'start_byte': 55746, 'token': 'and'},\n",
       " {'end_byte': 55756,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55750,\n",
       "  'token': 'became'},\n",
       " {'end_byte': 55760, 'html_token': False, 'start_byte': 55757, 'token': 'one'},\n",
       " {'end_byte': 55763, 'html_token': False, 'start_byte': 55761, 'token': 'of'},\n",
       " {'end_byte': 55771,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55764,\n",
       "  'token': 'Janeway'},\n",
       " {'end_byte': 55777, 'html_token': False, 'start_byte': 55771, 'token': \"'s\"},\n",
       " {'end_byte': 55784,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55778,\n",
       "  'token': 'valued'},\n",
       " {'end_byte': 55793,\n",
       "  'html_token': False,\n",
       "  'start_byte': 55785,\n",
       "  'token': 'officers'},\n",
       " {'end_byte': 55794, 'html_token': False, 'start_byte': 55793, 'token': '.'},\n",
       " {'end_byte': 55798, 'html_token': True, 'start_byte': 55794, 'token': '</P>'}]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = get_annotations(example)\n",
    "[t for t in example['document_tokens'] if t['start_byte'] >= ann['start_byte_ix'] and t['end_byte'] <= ann['end_byte_ix']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_nq import input_fn_builder\n",
    "seq_length=384\n",
    "\n",
    "name_to_features = {\n",
    "  \"input_ids\": tf.FixedLenFeature([], tf.int64),\n",
    "  \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "  \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "  \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "  \"start_bytes\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "  \"end_bytes\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "}\n",
    "name_to_features[\"start_positions\"] = tf.FixedLenFeature([], tf.int64)\n",
    "name_to_features[\"end_positions\"] = tf.FixedLenFeature([], tf.int64)\n",
    "\n",
    "def _decode_record(record):\n",
    "  \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "  example = tf.parse_single_example(record, name_to_features)\n",
    "  return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import run_nq\n",
    "bert_data_dir = '/data/nq/natural_questions/v1.0/'\n",
    "_train_path = '/Users/deniz/natural_questions/data/'\n",
    "_dev_path = os.path.join(bert_data_dir, 'dev')\n",
    "_train_path = os.path.join(bert_data_dir, 'train')\n",
    "train_files = [os.path.join(_train_path, _file) for _file in os.listdir(_train_path) if _file.endswith(\".tf_record\")]\n",
    "\n",
    "train_input_fn = input_fn_builder(\n",
    "  input_files=train_files,\n",
    "  seq_length=384,\n",
    "  is_training=True,\n",
    "  mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=173, shape=(32, 384), dtype=int64, numpy=\n",
       "array([[  101,  2043,  2106, ...,  3237,  1022,   102],\n",
       "       [  101,  2040,  2209, ..., 11411,  9358,   102],\n",
       "       [  101,  2073,  2515, ...,  1998,  6887,   102],\n",
       "       ...,\n",
       "       [  101,  2040,  6369, ...,  1005,  1005,   102],\n",
       "       [  101,  2040,  2001, ...,  8884,  2000,   102],\n",
       "       [  101,  2029,  1997, ...,  2086,  1010,   102]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "dt = tf.data.TFRecordDataset(train_files)\n",
    "dt = dt.map(_decode_record, num_parallel_calls=10)\n",
    "dt = dt.shuffle(buffer_size=100)\n",
    "dt = dt.batch(32)\n",
    "it = dt.make_one_shot_iterator()\n",
    "a = it.get_next()\n",
    "a['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=116, shape=(32,), dtype=int64, numpy=\n",
       "array([283,   0, 148,   0,   0, 290, 229,   0,  34, 162,   0,   0,  28,\n",
       "       101, 150,   0, 155,   0,   0,  27,   0,  48, 100, 304, 209,   0,\n",
       "       212,   0,   0, 131,  87,   0])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['start_positions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=111, shape=(32,), dtype=int64, numpy=\n",
       "array([341,   0, 151,   0,   0, 299, 243,   0,  43, 171,   0,   0,  47,\n",
       "       115, 152,   0, 155,   0,   0,  85,   0,  98, 101, 354, 321,   0,\n",
       "       212,   0,   0, 244,  93,   0])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['end_positions']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/home/deniz/repos/natural_questions/model/training', '_tf_random_seed': None, '_save_summary_steps': 50, '_save_checkpoints_steps': 10, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f26bc44e278>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "######### INFERENCE    ######\n",
    "#############################\n",
    "\n",
    "from run_nq import input_fn_builder\n",
    "bert_data_dir = '/data/nq/natural_questions/v1.0/'\n",
    "from bert import modeling\n",
    "from run_nq import model_fn_builder\n",
    "# prediction\n",
    "bert_config = modeling.BertConfig.from_json_file('model/uncased_L-12_H-768_A-12/bert_config.json')\n",
    "\n",
    "_dev_path = os.path.join(bert_data_dir, 'dev')\n",
    "_train_path = os.path.join(bert_data_dir, 'train')\n",
    "_predict_path = os.path.join(bert_data_dir, 'predict')\n",
    "\n",
    "config = tf.estimator.RunConfig(\n",
    "  save_checkpoints_steps=10, # this also sets when eval starts\n",
    "  save_summary_steps=50,\n",
    "  keep_checkpoint_max=10, #train_and_eval does not save the best models, but the most recent ones.\n",
    "  model_dir='/home/deniz/repos/natural_questions/model/training'\n",
    ")\n",
    "\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "  bert_config=bert_config,\n",
    "  init_checkpoint='/home/deniz/repos/natural_questions/model/training',\n",
    "  learning_rate=1e-5,\n",
    "  num_train_steps=10,\n",
    "  num_warmup_steps=0,\n",
    "  use_tpu=False,\n",
    "  use_one_hot_embeddings=False)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=config,\n",
    "  params={'batch_size':8})\n",
    "\n",
    "\n",
    "predict_files = [os.path.join(_train_path, _file) for _file in os.listdir(_train_path) if\n",
    "                 _file.endswith(\".tf_record\")]\n",
    "predict_input_fn = input_fn_builder(\n",
    "    input_files=predict_files,\n",
    "    seq_length=384,\n",
    "    is_training=False,\n",
    "    mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Estimator.predict at 0x7f26bc43ef10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_result = estimator.predict(predict_input_fn)\n",
    "batch_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_batch_result = next(batch_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 342)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(_batch_result['y_pred_start']), np.argmax(_batch_result['y_pred_end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295, 306)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GROUND TRUTH\n",
    "_batch_result['start_positions'], _batch_result['end_positions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.176463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>295</td>\n",
       "      <td>2.008699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>298</td>\n",
       "      <td>3.161665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299</td>\n",
       "      <td>4.229423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302</td>\n",
       "      <td>0.544027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1\n",
       "0    0  0.176463\n",
       "1  295  2.008699\n",
       "2  298  3.161665\n",
       "3  299  4.229423\n",
       "4  302  0.544027"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits = pd.DataFrame([(i, score) for i, score in enumerate(_batch_result['start_logits']) if score > 0 ])\n",
    "start_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.770081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>306</td>\n",
       "      <td>6.001465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>325</td>\n",
       "      <td>0.931091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>335</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>356</td>\n",
       "      <td>0.244597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>357</td>\n",
       "      <td>2.219360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1\n",
       "0    0  0.770081\n",
       "1  306  6.001465\n",
       "2  325  0.931091\n",
       "3  335  0.933333\n",
       "4  356  0.244597\n",
       "5  357  2.219360"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_logits = pd.DataFrame([(i, score) for i, score in enumerate(_batch_result['end_logits']) if score > 0 ])\n",
    "end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.061153622438558e-09"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "#####accuracy metric#####\n",
    "#########################\n",
    "\n",
    "tf.reset_default_graph()\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import metrics\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    start_ix = tf.expand_dims(tf.constant([10,20,30,40,50]),1)\n",
    "    end_ix =  tf.expand_dims(tf.constant([10,20,30,40,50]),1)\n",
    "    start_positions = tf.expand_dims(tf.constant([10,20,30,40,50]),1)\n",
    "    end_positions = tf.expand_dims(tf.constant([10,20,30,40,60]),1) #80% accuracy\n",
    "\n",
    "    y_pred = tf.concat([start_ix, end_ix], axis=-1) #[batch_size, 2]\n",
    "    y_true = tf.concat([start_positions, end_positions], axis=-1) #[batch_size, 2]\n",
    "    acc = tf.reduce_all(math_ops.equal(y_true, y_pred), axis=-1)\n",
    "    is_correct = math_ops.to_float(acc)\n",
    "    a,b = metrics.mean(is_correct)\n",
    "    \n",
    "    \n",
    "    running_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES)\n",
    "    running_vars_initializer = tf.variables_initializer(var_list=running_vars)\n",
    "    \n",
    "    sess.run(running_vars_initializer)\n",
    "    \n",
    "    # initial op\n",
    "    a_out = sess.run(a)\n",
    "    # update op\n",
    "    b_out = sess.run(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_out, b_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from preprocessing.preprocessing import *\n",
    "from run_nq import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_data_dir = \"/data/nq/natural_questions/v1.0/sample_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_files = [_file for _file in os.listdir(bert_data_dir) if _file.endswith(\".tf_record\")]\n",
    "_file_path = [os.path.join(bert_data_dir, _file) for _file in train_files]\n",
    "[tf.gfile.MakeDirs(_dir) for _dir in [_train_path, _dev_path]]\n",
    "print(_file_path)\n",
    "train_input_fn = input_fn_builder(\n",
    "    input_file=_file_path,\n",
    "    seq_length=512,\n",
    "    is_training=True,\n",
    "    drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['batch_size'] = 32\n",
    "_iter = train_input_fn(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_iter = _iter.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = _iter.get_next()\n",
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt['document_tokens'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = convert_examples_to_features(dt, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer\n",
    "if outputs:\n",
    "    print(outputs[0].targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{i: t for i, t in enumerate(outputs[0].tokens) if i >= outputs[0].targets[0][0] and i <= outputs[0].targets[0][1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_answer_start = dt['annotations'][0]['short_answers'][0]['start_byte']\n",
    "short_answer_end = dt['annotations'][0]['short_answers'][0]['end_byte']\n",
    "[t for t in dt['document_tokens'] if t['start_byte'] >= short_answer_start and t['end_byte'] <= short_answer_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_answer_start = dt['annotations'][0]['long_answer']['start_byte']\n",
    "long_answer_end = dt['annotations'][0]['long_answer']['end_byte']\n",
    "end = dt['annotations'][0]['long_answer']['end_token']+1\n",
    "start = dt['annotations'][0]['long_answer']['start_token']\n",
    "dt['document_tokens'][start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['document_tokens'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set([t['token'] for dt in data for t in dt['document_tokens'] if t['html_token']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(dt['document_html']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt['long_answer_candidates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['question_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['annotations'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = dt['document_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[token for token in tokens if token['start_byte'] >= start_byte_ix and token['end_byte'] <= end_byte_ix]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpuenv",
   "language": "python",
   "name": "tensorflow_gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
